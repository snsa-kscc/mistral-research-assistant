{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scraper(url: str):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        page_txt = soup.get_text(separator=\" \", strip=True)\n",
    "        return page_txt\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Failed to retrieve content from {url}, error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddg_search = DuckDuckGoSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(query: str, num_results: int = 3) -> list:\n",
    "    results = ddg_search.results(query, num_results)\n",
    "    return [r[\"link\"] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Summarize the following question based on the context:\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_llm = ChatOpenAI(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    temperature=0.1,\n",
    "    base_url=\"https://api.together.xyz\",\n",
    "    openai_api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = \"\"\"{text}\n",
    "\n",
    "-------------\n",
    "Using the above text summarize the following question:\n",
    "> {question}\n",
    "\n",
    "-------------\n",
    "if the question cannot be answered using the text, imply summarize the text. Include all factual information, numbers, stats, etc.\n",
    "\"\"\"\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_template(summary_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable_chain = (\n",
    "    RunnablePassthrough.assign(text=lambda x: web_scraper(x[\"url\"])[:10_000])\n",
    "    | summary_prompt\n",
    "    | t_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_chain = (\n",
    "    RunnablePassthrough.assign(urls=lambda x: web_search(x[\"question\"]))\n",
    "    | (lambda x: [{\"question\": x[\"question\"], \"url\": u} for u in x[\"urls\"]])\n",
    "    | runnable_chain.map()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Write 3 google search queries to serach online that form an \"\n",
    "            \"objective opinion from the following: {question}\\n\"\n",
    "            \"You must respond with a list of strings in the following format: \"\n",
    "            '[\"query1\", \"query2\", \"query3\"].\\n'\n",
    "            \"The queries must be as objective as possible.\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_questions_chain = search_prompt | t_llm | StrOutputParser() | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_questions(questions):\n",
    "    result = []\n",
    "    for q in questions:\n",
    "        result.append({\"question\": q})\n",
    "    return result\n",
    "\n",
    "\n",
    "composite_chain = generate_questions_chain | process_questions | duck_chain.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_system_prompt = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"\n",
    "\n",
    "research_report_template = \"\"\"Information:\n",
    "--------\n",
    "{research_summary}\n",
    "--------\n",
    "Using the above information, answer the following question or topic: \"{question}\" in a detailed report -- \\\n",
    "The report should focus on the answer to the question, should be well structured, informative, \\\n",
    "in depth, with facts and numbers if available and a minimum of 1,200 words.\n",
    "You should strive to write the report as long as you can using all relevant and necessary information provided.\n",
    "You must write the report with markdown syntax.\n",
    "You MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\n",
    "Write all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\n",
    "You must write the report in apa format.\n",
    "Please do your best, this is very important to my career.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", writer_system_prompt),\n",
    "        (\"user\", research_report_template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_list_of_lists(list_of_lists):\n",
    "    content = []\n",
    "    for l in list_of_lists:\n",
    "        content.append(\"\\n\\n\".join(l))\n",
    "    return \"\\n\\n\".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        research_summary=composite_chain | collapse_list_of_lists\n",
    "    )\n",
    "    | research_prompt\n",
    "    | t_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flatten_chain.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is the difference between langsmith and langchain?\",\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
